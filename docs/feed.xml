<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Caret Juice Marketing Blog</title>
  <subtitle>Marketing technology and automation minus the hype.</subtitle>
  <id>https://www.caretjuice.com/blog</id>
  <link href="https://www.caretjuice.com/blog"/>
  <link href="https://www.caretjuice.com/feed.xml" rel="self"/>
  <updated>2019-08-18T17:00:00-07:00</updated>
  <author>
    <name>Damon Gudaitis</name>
  </author>
  <entry>
    <title>Improve Your Data Quality With Human-Centered Process Design</title>
    <link rel="alternate" href="https://www.caretjuice.com/blog/improve-data-quality-human-centered-design.html"/>
    <id>https://www.caretjuice.com/blog/improve-data-quality-human-centered-design.html</id>
    <published>2019-08-18T17:00:00-07:00</published>
    <updated>2019-08-28T14:18:43-07:00</updated>
    <author>
      <name>Damon Gudaitis</name>
    </author>
    <summary type="html">&lt;p&gt;The more I work with data the more I appreciate how valuable quality data is and how hard it can be for an organization to maintain quality. Data multiplies as we add new business technologies. Much of the data produced by technologies is of good quality...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;The more I work with data the more I appreciate how valuable quality data is and how hard it can be for an organization to maintain quality. Data multiplies as we add new business technologies. Much of the data produced by technologies is of good quality if limited usefulness.&lt;/p&gt;

&lt;p&gt;More useful data comes from people. But asking people to produce data that is secondary to their reasons for interacting with a business technology is going to result in bad data.&lt;/p&gt;

&lt;p&gt;It doesn’t matter whether you are asking employees to go through these processes or your customers. Carrots and sticks deployed to entice and cajole help but are inadequate.&lt;/p&gt;

&lt;p&gt;Quality data has long been important to businesses but that is even more true now as machine learning pushes its way into all aspects of business.&lt;/p&gt;

&lt;p&gt;Computers are able to surface all sorts of obscure correlations within hundred- and thousand-dimensional data sets. However, the quality of machine predictions is dependant on the quality of the data on which the prediction is based.&lt;/p&gt;

&lt;p&gt;This is why Figure Eight, known as CrowdFlower at the time, found in 2016 that data scientists spend &lt;a href="https://visit.figure-eight.com/rs/416-ZBE-142/images/CrowdFlower_DataScienceReport_2016.pdf"&gt;almost 80 percent of their time collecting and cleaning data&lt;/a&gt; (pdf).&lt;/p&gt;

&lt;p&gt;A data scientist confronted with incomplete data can either delete the data or impute it. Neither of these choices is a good one. And poor-quality data is best dropped no matter how hard it was to collect.&lt;/p&gt;

&lt;p&gt;Analysts working with poor data are similarly stymied.&lt;/p&gt;

&lt;p&gt;Quality data is a competitive advantage. It helps people make better decisions that impact every aspect of the business.&lt;/p&gt;

&lt;p&gt;Dun and Bradstreet in their latest &lt;a href="https://www.dnb.com/content/dam/english/dnb-data-insight/sixth-annual-b2b-marketing-data-report-dnb.pdf"&gt;B2B Marketing Data Report&lt;/a&gt; (pdf) found that 89 percent of B-to-B marketers believe that “data quality is increasingly important to the sales and marketing organization” with 69 percent responding that it is extremely important.&lt;/p&gt;

&lt;h2&gt;Where data comes from human sources, quality data is difficult.&lt;/h2&gt;

&lt;p&gt;It doesn’t matter how many carrots or sticks that you deploy in service of getting people to create data that is secondary to the purpose of the process, data collection will slip and the quality of data will suffer.&lt;/p&gt;

&lt;p&gt;I’ve been a minor party to a couple of medium-sized CRM implementations. In both cases, getting managers together to think about what CRM systems can do for the organization led to someone deciding that adding a bunch of fields to lead record and getting front-line sales staff to complete the data was a good idea. &lt;/p&gt;

&lt;p&gt;The actual benefit never really materialized.&lt;/p&gt;

&lt;p&gt;Harvard Business Review has a piece on &lt;a href="https://hbr.org/2013/12/datas-credibility-problem"&gt;Data’s Credibility Problem&lt;/a&gt; from 2013 that identifies the gap between the people that produce data and people that consume it. The article proposes that communication is the solution to bridging this gap.&lt;/p&gt;

&lt;p&gt;Communication no doubt improves things. In one of the CRM implementations the front-line sales staff did buy in to collecting this data and it worked, for a time.&lt;/p&gt;

&lt;p&gt;Employees come and go and the importance of collecting this data slipped as the organization evolved.&lt;/p&gt;

&lt;p&gt;If you want to rely on front-line staff collecting data for you, you’re going to have to evangelize to your new staff the way you initially evangelized to the people who first collected the data.&lt;/p&gt;

&lt;p&gt;Even people who understand the value of this data can get distracted or lazy. But pretending for a minute that everyone has fantastic attention to detail, asking humans to collect data that’s going to be used by machines introduces mistakes that aren’t mistakes in a human context but are totally wrong in a machine one.&lt;/p&gt;

&lt;p&gt;Company names are a great example. If you have any kind of mix of people entering or importing company names to your CRM, go grab a CSV of lead or company records and start looking for duplicates (or often triplicates and x-plicates where x can get surprisingly high).&lt;/p&gt;

&lt;p&gt;You’ll see versions with “Inc” at the end and without. You’ll see “Inc” with and without the period. And you’ll see more of the same with LLP (or is it L.L.P.?) and GMBH.&lt;/p&gt;

&lt;p&gt;These are just corporate designations. Go look for companies with “and” in their names and see whether “and” is spelled out or in ampersand form.&lt;/p&gt;

&lt;p&gt;We intuitively recognize these duplicates as the same but to a machine they are different.&lt;/p&gt;

&lt;p&gt;Machine-data problems can have an effect on the human analysis. An analyst working with data processed by a machine, for example, might not get the opportunity to see that the same company appears multiple times when they query a database for the number of unique companies to use in a calculation.&lt;/p&gt;

&lt;p&gt;This problem is not exclusive to CRM-based processes. Your marketing automation system presents another, different example of how making data the object of your processes suffers versus making it a byproduct of process.&lt;/p&gt;

&lt;p&gt;I expect that most of you have seen an overloaded sign-up form asking everything about your business so that you can access a whitepaper or webinar or some such resource.&lt;/p&gt;

&lt;p&gt;I have been in charge of a number of forms like this, not by choice, and can verify that the data that you get from these forms is of generally low quality.&lt;/p&gt;

&lt;p&gt;Some people get annoyed by the forms and just enter in random information to get to whatever it is they are trying to access. Others don’t know some of the information, like annual revenue, and just make things up.&lt;/p&gt;

&lt;p&gt;That’s just the data you see. People abandon cumbersome forms leaving you with no data on a company that may have been in the market.&lt;/p&gt;

&lt;p&gt;It may seem a little counterintuitive to compare data collected through internal processes in CRM and similar systems with public facing data collection in marketing automation systems. However, the principle for fixing these processes is the same.&lt;/p&gt;

&lt;h2&gt;Quality data is a byproduct of processes designed to support the success of the people who undertake them&lt;/h2&gt;

&lt;p&gt;Data quality is a business problem rather than an IT problem. The previous Harvard Business Review article recognizes this and rightly identifies communication as a possible solution. However, communication is a constant challenge that requires regular attention. There are many other important things that need to be communicated and only so much capacity for communicating or receiving communications.&lt;/p&gt;

&lt;p&gt;Human-centered design provides techniques for uncovering the needs and motivations of the people at the center of an interaction so that you can then engineer problems out of existence.&lt;/p&gt;

&lt;p&gt;When you are designing processes, data needs to be a secondary concern. No matter how much buy-in that you get from the people who will be undertaking the processes, the quality of data will slip over time. People will move on. New employees will come in. People will be busy or having a bad day. Or they’ll just make mistakes.&lt;/p&gt;

&lt;p&gt;In both of the previous CRM and marketing automation examples, data is the object of the process. That’s missing the point. Success should be the object of any process.&lt;/p&gt;

&lt;p&gt;The more your processes are oriented around the success of the people at the center of them, the better your adoption of the processes will be. The better the adoption, the better the quality of the data.&lt;/p&gt;

&lt;p&gt;You can still tweak your processes to suit your data needs. Just make sure that success is the goal.&lt;/p&gt;

&lt;p&gt;One way to do this is to enrich your first-party system data with third-party data. If knowing the industry of the people in your database is of value, then third-party data sources, imperfect thought they may be, will be of better quality than if you ask people to collect this data. You’ll also solve all of those company name problems in your CRM this way and make it easier for people to complete your process.&lt;/p&gt;

&lt;p&gt;Automated date enrichment streamilines both internal and public-facing processes which should increase efficiency and encourage the successful completion of the processes.&lt;/p&gt;

&lt;p&gt;Using third-party data to enrich your first-party data and replace manually collected data is an intuitive way to improve data quality while keeping your processes focused on the success of the people who have to do them.&lt;/p&gt;

&lt;p&gt;Another, more fundamental way of improving data quality is to re-imagine processes to put the data at the core of what constitutes success.&lt;/p&gt;

&lt;p&gt;For example if industry is important to you, instead of asking for a prospect to fill out an industry field when they want to download something create industry specific resources, like case studies, people the opportunity to select the industry-related resource that best helps them do whatever it is they are trying to do.&lt;/p&gt;

&lt;p&gt;Most sales and marketing processes are designed using empathy and intuition for the users.&lt;/p&gt;

&lt;p&gt;Human-centered design is effective because of the research that goes in to uncovering the motivations at the core of an interaction including observation and interviews. Empathy and intuition are fantastic things to have, but you can’t scale it across your team.&lt;/p&gt;

&lt;p&gt;Processes that put researching the users before designing for them may take more time, but they also scale and you don’t need to rely on the empathic genius of a few individuals in your team.&lt;/p&gt;

&lt;p&gt;This sort of qualitative, user research doesn’t need to be statistically significant in order to have value. Get ideas for what sort of motivations are at the core of a particular interaction and then use your A/B testing tools to figure out whether a particular research conclusion is statistically significant.&lt;/p&gt;

&lt;p&gt;Put in the effort to research your users’ goals and motivations and be sure that you are supporting the individual’s short-term goals. The data you collect will support your long-term sales and marketing efforts much more effectively this way.&lt;/p&gt;

&lt;p&gt;When you start questioning whether the object of the data you collect supports the success of people who are undertaking your processes you will find plenty of opportunities for flipping data collection around to support their short-term success while aligning with your long-term needs.&lt;/p&gt;

&lt;p&gt;And because they actually benefit from giving you data, you’ll get more accurate results. Which will make your data more useful.&lt;/p&gt;

&lt;p&gt;Discuss on &lt;a href="https://www.linkedin.com/feed/update/urn:li:activity:6569316198499045377/"&gt;LinkedIn&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>US Population Data for Google Analytics</title>
    <link rel="alternate" href="https://www.caretjuice.com/blog/geo-data-for-ga.html"/>
    <id>https://www.caretjuice.com/blog/geo-data-for-ga.html</id>
    <published>2019-03-12T17:00:00-07:00</published>
    <updated>2019-03-13T11:12:30-07:00</updated>
    <author>
      <name>Damon Gudaitis</name>
    </author>
    <summary type="html">&lt;p&gt;Geography data import in Google Analytics is a lesser-used feature. In their docs, Google emphasizes the ability to create custom sales districts. While this is quite useful for the right type of business, you can also use geo-data import to augment...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;Geography data import in Google Analytics is a lesser-used feature. In their docs, Google emphasizes the ability to create custom sales districts. While this is quite useful for the right type of business, you can also use geo-data import to augment your data.&lt;/p&gt;

&lt;p&gt;Please note, this covers how to format the data for Google. If you just want to import the data that I&amp;rsquo;ve formatted, skip to the end of this post, grab the CSV and follow the instructions in the last section.&lt;/p&gt;

&lt;p&gt;Google lets you match your imported data to City ID, Country ISO code, Region ID, and Sub-Continent Code so to start you’ll want some data that you can match at that level.&lt;/p&gt;

&lt;p&gt;Additionally, you can only import custom dimensions this way. This isn’t really a problem but it means that you’ll probably need to do some pre-processing of your data to, for example, turn numerical data in to buckets that are suitable as dimensions.&lt;/p&gt;

&lt;p&gt;I looked at importing raw numerical data and then bucketing the data via custom segments, but GA doesn’t let you create segments using less than or greater than operators and doing this via regular expressions seems like a quick way to give myself nightmares.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s look at &lt;a href="'https://developers.google.com/analytics/devguides/collection/protocol/v1/geoid'"&gt;Google&amp;rsquo;s geo data&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="python"&gt;
import pandas as pd
import numpy as np

ga = pd.read_csv(&amp;#39;geotargets-2019-02-11.csv&amp;#39;)
ga.head()

&lt;/code&gt;&lt;/pre&gt;

&lt;div class="dataframe-wrapper"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Criteria ID&lt;/th&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Canonical Name&lt;/th&gt;
      &lt;th&gt;Parent ID&lt;/th&gt;
      &lt;th&gt;Country Code&lt;/th&gt;
      &lt;th&gt;Target Type&lt;/th&gt;
      &lt;th&gt;Status&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1000002&lt;/td&gt;
      &lt;td&gt;Kabul&lt;/td&gt;
      &lt;td&gt;Kabul,Kabul,Afghanistan&lt;/td&gt;
      &lt;td&gt;9075393.0&lt;/td&gt;
      &lt;td&gt;AF&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1000003&lt;/td&gt;
      &lt;td&gt;Luanda&lt;/td&gt;
      &lt;td&gt;Luanda,Luanda Province,Angola&lt;/td&gt;
      &lt;td&gt;9070431.0&lt;/td&gt;
      &lt;td&gt;AO&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1000004&lt;/td&gt;
      &lt;td&gt;The Valley&lt;/td&gt;
      &lt;td&gt;The Valley,Anguilla&lt;/td&gt;
      &lt;td&gt;2660.0&lt;/td&gt;
      &lt;td&gt;AI&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1000010&lt;/td&gt;
      &lt;td&gt;Abu Dhabi&lt;/td&gt;
      &lt;td&gt;Abu Dhabi,Abu Dhabi,United Arab Emirates&lt;/td&gt;
      &lt;td&gt;9041082.0&lt;/td&gt;
      &lt;td&gt;AE&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1000011&lt;/td&gt;
      &lt;td&gt;Ajman&lt;/td&gt;
      &lt;td&gt;Ajman,Ajman,United Arab Emirates&lt;/td&gt;
      &lt;td&gt;9047096.0&lt;/td&gt;
      &lt;td&gt;AE&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h2&gt;Google Analytics Geo Data&lt;/h2&gt;

&lt;p&gt;GA uses the Criteria ID to match city data so we need to find a way to match our external data with this ID.&lt;/p&gt;

&lt;p&gt;For that, we can replicate the Canonical Name in our external data without too much manual intervention and then merge the two data sets on Canonical Name before uploading the merged data to GA.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s not evident in the above sample, but there are many more &lt;em&gt;Target Types&lt;/em&gt; than just the four entities that we can match to GA data. The techniques I describe here would be fantastic when combined with Zip/Postal Code census data to analyze conversion rates by average household income.&lt;/p&gt;

&lt;p&gt;However, Google&amp;rsquo;s geo data is used for more products than just GA, Ads being a prime example. It doesn&amp;rsquo;t seem like you can back door postal code and other data types into GA using the data import feature.&lt;/p&gt;

&lt;pre&gt;&lt;code class="python"&gt;ga[&amp;#39;Target Type&amp;#39;].value_counts()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Postal Code               48390
City                      38101
Neighborhood               4666
County                     3417
Municipality               2117
Province                   1131
District                    948
Region                      909
Congressional District      441
Airport                     395
Department                  240
State                       235
University                  219
Country                     213
City Region                 183
Governorate                 121
National Park                96
Borough                      88
Prefecture                   49
Okrug                        28
Canton                       26
Autonomous Community         22
TV Region                    14
Union Territory               7
Territory                     4
Name: Target Type, dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The basic pattern for city canonicals seems to be &lt;em&gt;City,State,Country&lt;/em&gt;. However, a deeper look into the data reveals that this pattern doesn&amp;rsquo;t hold one-hundred percent of the time as there are sometimes multiple non-city entities that would have naming collisions if without modifying the canonical. As a result, some cities canonicalize to &lt;em&gt;City,City,State,Country&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Luckily, these collisions don&amp;rsquo;t seem to be a problem if you remove the non-city entities from this data. So we&amp;rsquo;re going to remove anything that isn&amp;rsquo;t a city.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll be matching US city population data in this example, so let&amp;rsquo;s also remove the non-US data.&lt;/p&gt;

&lt;pre&gt;&lt;code class="python"&gt;
ga = ga[ga[&amp;#39;Country Code&amp;#39;] == &amp;#39;US&amp;#39;]
ga = ga[ga[&amp;#39;Target Type&amp;#39;] == &amp;#39;City&amp;#39;]
ga.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div class="dataframe-wrapper"&gt;

&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Criteria ID&lt;/th&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Canonical Name&lt;/th&gt;
      &lt;th&gt;Parent ID&lt;/th&gt;
      &lt;th&gt;Country Code&lt;/th&gt;
      &lt;th&gt;Target Type&lt;/th&gt;
      &lt;th&gt;Status&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;10642&lt;/th&gt;
      &lt;td&gt;1012873&lt;/td&gt;
      &lt;td&gt;Anchorage&lt;/td&gt;
      &lt;td&gt;Anchorage,Anchorage,Alaska,United States&lt;/td&gt;
      &lt;td&gt;21132.0&lt;/td&gt;
      &lt;td&gt;US&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10643&lt;/th&gt;
      &lt;td&gt;1012874&lt;/td&gt;
      &lt;td&gt;Anderson&lt;/td&gt;
      &lt;td&gt;Anderson,Alaska,United States&lt;/td&gt;
      &lt;td&gt;21132.0&lt;/td&gt;
      &lt;td&gt;US&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10644&lt;/th&gt;
      &lt;td&gt;1012875&lt;/td&gt;
      &lt;td&gt;Angoon&lt;/td&gt;
      &lt;td&gt;Angoon,Alaska,United States&lt;/td&gt;
      &lt;td&gt;21132.0&lt;/td&gt;
      &lt;td&gt;US&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10645&lt;/th&gt;
      &lt;td&gt;1012876&lt;/td&gt;
      &lt;td&gt;Atqasuk&lt;/td&gt;
      &lt;td&gt;Atqasuk,Alaska,United States&lt;/td&gt;
      &lt;td&gt;21132.0&lt;/td&gt;
      &lt;td&gt;US&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10646&lt;/th&gt;
      &lt;td&gt;1012877&lt;/td&gt;
      &lt;td&gt;Utqiagvik&lt;/td&gt;
      &lt;td&gt;Utqiagvik,Alaska,United States&lt;/td&gt;
      &lt;td&gt;21132.0&lt;/td&gt;
      &lt;td&gt;US&lt;/td&gt;
      &lt;td&gt;City&lt;/td&gt;
      &lt;td&gt;Active&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;You can see Anchorage as an example of a canonical that uses the &lt;em&gt;City,City,State,Country&lt;/em&gt; pattern.&lt;/p&gt;

&lt;p&gt;Another pattern that is used to avoid collisions is &lt;em&gt;City,County,State,Country&lt;/em&gt;. Luckily Google seems to add &amp;ldquo;County&amp;rdquo; to the end of every county name so this will be fairly easy to detect and fix.&lt;/p&gt;

&lt;p&gt;In addition, a little birdie told me that we&amp;rsquo;re going to have problems with matching &amp;ldquo;Saint&amp;rdquo; and &amp;ldquo;St.&amp;rdquo; as well as consitently matching names with &amp;ldquo;Town&amp;rdquo; and &amp;ldquo;Township&amp;rdquo; in city names.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s make canonicals that are more useful to us by using just the &lt;em&gt;City,State,Country&lt;/em&gt; pattern, standardizing all names to use &amp;ldquo;St.&amp;rdquo; rather than &amp;ldquo;Saint&amp;rdquo; and drop &amp;ldquo;Town&amp;rdquo; and &amp;ldquo;Township&amp;rdquo; from names.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll drop some columns that we&amp;rsquo;re done with while we&amp;rsquo;re at it. Please note I spent days comparing source and formatted columns for potential collisions and errors before dropping any data. If you&amp;rsquo;re following along with another data set, don&amp;rsquo;t drop anything just yet.&lt;/p&gt;

&lt;pre&gt;&lt;code class="python"&gt;
import re
no_match = []
def ga_format_temp_canonical(string):
  if &amp;quot;Saint&amp;quot; in string:
    string = string.replace(&amp;#39;Saint&amp;#39;, &amp;#39;St.&amp;#39;)
  if &amp;quot;Township&amp;quot; in string:
    string = string.replace(&amp;#39; Township&amp;#39;, &amp;#39;&amp;#39;)
  if &amp;quot; Town&amp;quot; in string:
    string = string.replace(&amp;#39; Town&amp;#39;, &amp;#39;&amp;#39;)
  #find and remove County
  match = re.search(r&amp;quot;^([\w \-\.\/]+),([\w ]+) County,(.*)&amp;quot;, string)
  if match:
    string = match.group(1) + &amp;#39;,&amp;#39; + match.group(3)
  #find and remove duplicate City patterns
  match = re.search(r&amp;quot;^([\w \-\.\/]+),([\w ]+),(.*)&amp;quot;, string)
  if match:
    if match.group(1) == match.group(2):
      string = match.group(2) + &amp;#39;,&amp;#39; + match.group(3)
      return string
    else:
      return string
  else:
    no_match.append(string) #for finding holes in our regex
    return string
  return &amp;quot;Function failed&amp;quot;



ga[&amp;#39;Temp Canonical&amp;#39;] = ga[&amp;#39;Canonical Name&amp;#39;].apply(ga_format_temp_canonical)


ga = ga.drop([&amp;#39;Name&amp;#39;,&amp;#39;Canonical Name&amp;#39;, &amp;#39;Parent ID&amp;#39;, &amp;#39;Country Code&amp;#39;, &amp;#39;Target Type&amp;#39;, &amp;#39;Status&amp;#39;], axis=1)
ga.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div class="dataframe-wrapper"&gt;

&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Criteria ID&lt;/th&gt;
      &lt;th&gt;Temp Canonical&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;10642&lt;/th&gt;
      &lt;td&gt;1012873&lt;/td&gt;
      &lt;td&gt;Anchorage,Alaska,United States&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10643&lt;/th&gt;
      &lt;td&gt;1012874&lt;/td&gt;
      &lt;td&gt;Anderson,Alaska,United States&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10644&lt;/th&gt;
      &lt;td&gt;1012875&lt;/td&gt;
      &lt;td&gt;Angoon,Alaska,United States&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10645&lt;/th&gt;
      &lt;td&gt;1012876&lt;/td&gt;
      &lt;td&gt;Atqasuk,Alaska,United States&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10646&lt;/th&gt;
      &lt;td&gt;1012877&lt;/td&gt;
      &lt;td&gt;Utqiagvik,Alaska,United States&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h2&gt;US Census Data&lt;/h2&gt;

&lt;p&gt;So for this exercise, I&amp;rsquo;m going to grab &lt;a href="https://www.census.gov/data/tables/2017/demo/popest/total-cities-and-towns.html"&gt;city and town population data from the US census&lt;/a&gt;. This dataset is particularly convenient because it is offered in CSV format without any need for scraping or other processing. It is also very thorough as it includes geographical estimates for the entire US population.&lt;/p&gt;

&lt;p&gt;By comparison, Canadian data seems to be limited to actual cities (as defined by their respective provinces) or broken out into census geo codes that need to be remapped separately.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s grab the US data and look at it.&lt;/p&gt;

&lt;pre&gt;&lt;code class="python"&gt;
us = pd.read_csv(&amp;#39;sub-est2017_all.csv&amp;#39;, encoding = &amp;quot;ISO-8859-1&amp;quot;)
us.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div class="dataframe-wrapper"&gt;

&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;SUMLEV&lt;/th&gt;
      &lt;th&gt;STATE&lt;/th&gt;
      &lt;th&gt;COUNTY&lt;/th&gt;
      &lt;th&gt;PLACE&lt;/th&gt;
      &lt;th&gt;COUSUB&lt;/th&gt;
      &lt;th&gt;CONCIT&lt;/th&gt;
      &lt;th&gt;PRIMGEO_FLAG&lt;/th&gt;
      &lt;th&gt;FUNCSTAT&lt;/th&gt;
      &lt;th&gt;NAME&lt;/th&gt;
      &lt;th&gt;STNAME&lt;/th&gt;
      &lt;th&gt;CENSUS2010POP&lt;/th&gt;
      &lt;th&gt;ESTIMATESBASE2010&lt;/th&gt;
      &lt;th&gt;POPESTIMATE2010&lt;/th&gt;
      &lt;th&gt;POPESTIMATE2011&lt;/th&gt;
      &lt;th&gt;POPESTIMATE2012&lt;/th&gt;
      &lt;th&gt;POPESTIMATE2013&lt;/th&gt;
      &lt;th&gt;POPESTIMATE2014&lt;/th&gt;
      &lt;th&gt;POPESTIMATE2015&lt;/th&gt;
      &lt;th&gt;POPESTIMATE2016&lt;/th&gt;
      &lt;th&gt;POPESTIMATE2017&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;4779736&lt;/td&gt;
      &lt;td&gt;4780135&lt;/td&gt;
      &lt;td&gt;4785579&lt;/td&gt;
      &lt;td&gt;4798649&lt;/td&gt;
      &lt;td&gt;4813946&lt;/td&gt;
      &lt;td&gt;4827660&lt;/td&gt;
      &lt;td&gt;4840037&lt;/td&gt;
      &lt;td&gt;4850858&lt;/td&gt;
      &lt;td&gt;4860545&lt;/td&gt;
      &lt;td&gt;4874747&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;124&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;Abbeville city&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;2688&lt;/td&gt;
      &lt;td&gt;2688&lt;/td&gt;
      &lt;td&gt;2684&lt;/td&gt;
      &lt;td&gt;2677&lt;/td&gt;
      &lt;td&gt;2629&lt;/td&gt;
      &lt;td&gt;2612&lt;/td&gt;
      &lt;td&gt;2595&lt;/td&gt;
      &lt;td&gt;2587&lt;/td&gt;
      &lt;td&gt;2575&lt;/td&gt;
      &lt;td&gt;2567&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;460&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;Adamsville city&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;4522&lt;/td&gt;
      &lt;td&gt;4522&lt;/td&gt;
      &lt;td&gt;4516&lt;/td&gt;
      &lt;td&gt;4502&lt;/td&gt;
      &lt;td&gt;4479&lt;/td&gt;
      &lt;td&gt;4457&lt;/td&gt;
      &lt;td&gt;4437&lt;/td&gt;
      &lt;td&gt;4409&lt;/td&gt;
      &lt;td&gt;4376&lt;/td&gt;
      &lt;td&gt;4347&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;484&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;Addison town&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;758&lt;/td&gt;
      &lt;td&gt;754&lt;/td&gt;
      &lt;td&gt;751&lt;/td&gt;
      &lt;td&gt;751&lt;/td&gt;
      &lt;td&gt;744&lt;/td&gt;
      &lt;td&gt;743&lt;/td&gt;
      &lt;td&gt;740&lt;/td&gt;
      &lt;td&gt;734&lt;/td&gt;
      &lt;td&gt;734&lt;/td&gt;
      &lt;td&gt;728&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;676&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;Akron town&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;356&lt;/td&gt;
      &lt;td&gt;356&lt;/td&gt;
      &lt;td&gt;355&lt;/td&gt;
      &lt;td&gt;345&lt;/td&gt;
      &lt;td&gt;345&lt;/td&gt;
      &lt;td&gt;341&lt;/td&gt;
      &lt;td&gt;337&lt;/td&gt;
      &lt;td&gt;335&lt;/td&gt;
      &lt;td&gt;332&lt;/td&gt;
      &lt;td&gt;332&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Well that&amp;rsquo;s an easy way to get a headache.&lt;/p&gt;

&lt;p&gt;Once again presenting a veneer of confidence that masks the trial and error that went in to producing this, let&amp;rsquo;s fix this data and drop everything we don&amp;rsquo;t need.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re going to take the name and state name fields and fuse them together with some commas and a country name to match against the &lt;em&gt;Temp Canonical&lt;/em&gt; that we created in the GA set.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t know what the &lt;em&gt;PRIMGEO_FLAG&lt;/em&gt;, or primitive geography flag, is for. But what it does is duplicate all of the data. Let&amp;rsquo;s drop every row where it equals 0. This will also have the side-benefit of removing state populations from our data.&lt;/p&gt;

&lt;p&gt;If you look through the source data, you will see all sorts of post-fixes in the &lt;em&gt;NAME&lt;/em&gt; field like &lt;em&gt;city&lt;/em&gt; and &lt;em&gt;charter township&lt;/em&gt;. We&amp;rsquo;ll need to drop them and while we&amp;rsquo;re at it we&amp;rsquo;re going to make sure &amp;ldquo;Saint,&amp;rdquo; &amp;ldquo;Township,&amp;rdquo; and &amp;ldquo;Town&amp;rdquo; are standardized the same way as our Google data.&lt;/p&gt;

&lt;p&gt;This will create quite a few duplicate canonicals. The (pt.) post-fix stands for part and to match the Google data we want to amalgamate everything and look at the whole. So we&amp;rsquo;ll do that, sum the 2017 population estimate and drop all of the other fields in the process.&lt;/p&gt;

&lt;p&gt;Finally, we&amp;rsquo;ll drop rural and county data that isn&amp;rsquo;t located in a town or city that we can match to the Google data.&lt;/p&gt;

&lt;pre&gt;&lt;code class="python"&gt;
us = us[us[&amp;#39;PRIMGEO_FLAG&amp;#39;] != 0]

def format_canonical_name(city, state):
  #US data uses St. for Saint consistently, Google is mixed so standardize on US
  if &amp;quot;Saint&amp;quot; in city:
    city = city.replace(&amp;#39;Saint&amp;#39;, &amp;#39;St.&amp;#39;)
  if &amp;quot;Township&amp;quot; in city:
    city = city.replace(&amp;#39; Township&amp;#39;, &amp;#39;&amp;#39;)
  if &amp;quot; Town&amp;quot; in city:
    city = city.replace(&amp;#39; Town&amp;#39;, &amp;#39;&amp;#39;)
  #Careful with the order here
  if city.endswith(&amp;#39; city and borough&amp;#39;):
    city = city[:-17]
  elif city.endswith(&amp;#39; charter township&amp;#39;):
    city = city[:-17]
  elif city.endswith(&amp;#39; municipality&amp;#39;):
    city = city[:-13]
  elif city.endswith(&amp;#39; city&amp;#39;):
    city = city[:-5]
  elif city.endswith(&amp;#39; town&amp;#39;):
    city = city[:-5]
  elif city.endswith(&amp;#39; borough&amp;#39;):
    city = city[:-8]
  elif city.endswith(&amp;#39; city (pt.)&amp;#39;):
    city  = city[:-11]
  elif city.endswith(&amp;#39; township&amp;#39;):
    city = city[:-9]
  elif city.endswith(&amp;#39; village&amp;#39;):
    city = city[:-8]
  elif city.endswith(&amp;#39; charter&amp;#39;):
    city = city[:-8]
  elif city.endswith(&amp;#39; town (pt.)&amp;#39;):
    city = city[:-11]
  elif city.endswith(&amp;#39; borough (pt.)&amp;#39;):
    city = city[:-14]
  elif city.endswith(&amp;#39; village (pt.)&amp;#39;):
    city = city[:-14]
  elif city.endswith(&amp;#39; city (balance) (pt.)&amp;#39;):
    city = city[:-21]
  elif city.endswith(&amp;#39; city (balance)&amp;#39;):
    city = city[:-15]
  return city + &amp;#39;,&amp;#39; + state +&amp;#39;,United States&amp;#39;

us[[&amp;#39;Temp Canonical&amp;#39;]] = us.apply( lambda row: pd.Series(format_canonical_name(row[8], row[9])), axis=1 )

us = us.groupby([&amp;#39;Temp Canonical&amp;#39;], as_index=False)[&amp;#39;POPESTIMATE2017&amp;#39;].sum()

#sometimes we can&amp;#39;t automatically generate working canonicals
manual_interventions = {
    &amp;#39;Nashville-Davidson metropolitan government (balance),Tennessee,United States&amp;#39;: &amp;#39;Nashville,Tennessee,United States&amp;#39;,
    &amp;#39;Louisville/Jefferson County metro government (balance),Kentucky,United States&amp;#39;: &amp;#39;Louisville,Kentucky,United States&amp;#39;,
    &amp;#39;Urban Honolulu CDP,Hawaii,United States&amp;#39;: &amp;#39;Honolulu,Hawaii,United States&amp;#39;,
    &amp;#39;Lexington-Fayette urban county,Kentucky,United States&amp;#39;: &amp;#39;Lexington,Kentucky,United States&amp;#39;,
    &amp;#39;Boise City,Idaho,United States&amp;#39;: &amp;#39;Boise,Idaho,United States&amp;#39;,
    &amp;#39;San Buenaventura (Ventura),California,United States&amp;#39;: &amp;#39;Ventura,California,United States&amp;#39;,
    &amp;#39;New York,New York,United States&amp;#39;: &amp;#39;New York,United States&amp;#39;,
    &amp;#39;Union City,Ohio,United States&amp;#39;: &amp;#39;Union,Ohio,United States&amp;#39;,
    &amp;#39;Penn Run,Pennsylvania,United States&amp;#39;: &amp;#39;Penn,Pennsylvania,United States&amp;#39;,
    &amp;#39;Lakewood,Pierce,Washington,United States&amp;#39;: &amp;#39;Lakewood,Washington,United States&amp;#39;,        
}
for key, value in manual_interventions.items():
  us.loc[us[&amp;#39;Temp Canonical&amp;#39;] == key, &amp;#39;Temp Canonical&amp;#39; ] = value

#We&amp;#39;re only interested in urban population
us = us[~us[&amp;#39;Temp Canonical&amp;#39;].str.startswith(&amp;#39;Balance of&amp;#39;)  ]

#Let&amp;#39;s also get rid of county data
us = us[~us[&amp;#39;Temp Canonical&amp;#39;].str.contains(&amp;#39;County&amp;#39;)]


us.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div class="dataframe-wrapper"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Temp Canonical&lt;/th&gt;
      &lt;th&gt;POPESTIMATE2017&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Aastad,Minnesota,United States&lt;/td&gt;
      &lt;td&gt;213&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Abbeville,Alabama,United States&lt;/td&gt;
      &lt;td&gt;2567&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Abbeville,Georgia,United States&lt;/td&gt;
      &lt;td&gt;2789&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Abbeville,Louisiana,United States&lt;/td&gt;
      &lt;td&gt;12272&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Abbeville,Mississippi,United States&lt;/td&gt;
      &lt;td&gt;436&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h2&gt;Blending US and GA Datasets&lt;/h2&gt;

&lt;p&gt;Now we merge the datasets. We&amp;rsquo;ll rename some columns while we&amp;rsquo;re at it.&lt;/p&gt;

&lt;pre&gt;&lt;code class="python"&gt;
us_ga = pd.merge(ga, us, on=&amp;quot;Temp Canonical&amp;quot;, suffixes=(&amp;#39;_ga&amp;#39;,&amp;#39;_us&amp;#39;), how=&amp;quot;inner&amp;quot; )
us_ga.rename(columns={&amp;#39;Criteria ID&amp;#39;: &amp;#39;ga:cityId&amp;#39;, &amp;#39;POPESTIMATE2017&amp;#39;: &amp;#39;2017&amp;#39;}, inplace=True)
us_ga.set_index(&amp;#39;ga:cityId&amp;#39;)
us_ga.head()

&lt;/code&gt;&lt;/pre&gt;

&lt;div class="dataframe-wrapper"&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ga:cityId&lt;/th&gt;
      &lt;th&gt;Temp Canonical&lt;/th&gt;
      &lt;th&gt;2017&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1012873&lt;/td&gt;
      &lt;td&gt;Anchorage,Alaska,United States&lt;/td&gt;
      &lt;td&gt;294356&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1012874&lt;/td&gt;
      &lt;td&gt;Anderson,Alaska,United States&lt;/td&gt;
      &lt;td&gt;337&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1012875&lt;/td&gt;
      &lt;td&gt;Angoon,Alaska,United States&lt;/td&gt;
      &lt;td&gt;452&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1012876&lt;/td&gt;
      &lt;td&gt;Atqasuk,Alaska,United States&lt;/td&gt;
      &lt;td&gt;244&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1012878&lt;/td&gt;
      &lt;td&gt;Bethel,Alaska,United States&lt;/td&gt;
      &lt;td&gt;6456&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Sort the cities into buckets by population.&lt;/p&gt;

&lt;pre&gt;&lt;code class="python"&gt;
a = us_ga[&amp;#39;2017&amp;#39;].tolist()
a.sort()
p = sum(a) / 5
curr_percentile = p
q = []
q.append(min(a) -1 )
r = 0
for each in a:    
    if r &amp;lt; curr_percentile:
        r = r + each
    else:
        q.append(each + 1)
        r = r + each
        curr_percentile = curr_percentile + p
q.append(max(a) +1)

labels = [&amp;#39;small town&amp;#39;, &amp;#39;town&amp;#39;, &amp;#39;large town&amp;#39;,&amp;#39;city&amp;#39;,&amp;#39;major city&amp;#39;]

us_ga[&amp;#39;quintile&amp;#39;] = pd.cut(us_ga[&amp;#39;2017&amp;#39;], q, include_lowest=True, labels=labels)

#check that our buckets are roughly equal
us_ga.groupby(&amp;#39;quintile&amp;#39;)[&amp;#39;2017&amp;#39;].sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;quintile
small town    43610647
town          43637694
large town    43716638
city          44237984
major city    42709542
Name: 2017, dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="python"&gt;
#GA throws an error if there are columns in your csv that you don&amp;#39;t use
us_ga = us_ga.drop(columns=[&amp;#39;Temp Canonical&amp;#39;, &amp;#39;2017&amp;#39;], axis=1)
#export to CSV
us_ga.to_csv(&amp;#39;us-geo-ga.csv&amp;#39;, index=False)
#we dropped the index column from the CSV
us_ga.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div class="dataframe-wrapper"&gt;

&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ga:cityId&lt;/th&gt;
      &lt;th&gt;quintile&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1012873&lt;/td&gt;
      &lt;td&gt;city&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1012874&lt;/td&gt;
      &lt;td&gt;small town&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1012875&lt;/td&gt;
      &lt;td&gt;small town&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1012876&lt;/td&gt;
      &lt;td&gt;small town&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1012878&lt;/td&gt;
      &lt;td&gt;small town&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h2&gt;Google Analytics Data Import&lt;/h2&gt;

&lt;p&gt;From here on we are following &lt;a href="https://support.google.com/analytics/answer/6160509?ref_topic=6015090"&gt;Google&amp;rsquo;s documentation&lt;/a&gt; starting at Step 3. If you need more detailed instructions, I encourage you to go to there.&lt;/p&gt;

&lt;p&gt;You can just &lt;a href="/blog/geo-data-for-ga/us_city_pop_ga.csv"&gt;grab the finished CSV&lt;/a&gt; and following along from here.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create a Custom Dimension with session scope.&lt;/li&gt;
&lt;li&gt;Create a Data Set (under Admin &amp;gt; Property &amp;gt; Data Import) where you assign the newly created Custom Dimension to the import.&lt;/li&gt;
&lt;li&gt;At the end of the Data Set creation dialogue, copy the dimension ID (it will look like ga:dimension10).&lt;/li&gt;
&lt;li&gt;Open the CSV, replace &amp;ldquo;quintile&amp;rdquo; with the dimension ID and save it again as a CSV.&lt;/li&gt;
&lt;li&gt;Upload the CSV manually (Admin &amp;gt; Property &amp;gt; Data Import) select the Data Set you created previously and Manage Uploads.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And there, you&amp;rsquo;re done.&lt;/p&gt;

&lt;p&gt;Discuss on &lt;a href="https://www.linkedin.com/feed/update/urn:li:activity:6511659733227749377/"&gt;LinkedIn&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Hackers' Guide to Speech to Text&amp;#58; Quick, Dirty, and Free</title>
    <link rel="alternate" href="https://www.caretjuice.com/blog/speech-to-text.html"/>
    <id>https://www.caretjuice.com/blog/speech-to-text.html</id>
    <published>2018-11-19T16:00:00-08:00</published>
    <updated>2019-03-12T13:19:24-07:00</updated>
    <author>
      <name>Damon Gudaitis</name>
    </author>
    <summary type="html">&lt;p&gt;So you’ve got some audio that you want to turn into text? There are a lot of good, inexpensive options out there powered by machines, people, and a mix of the two. &lt;/p&gt;

&lt;p&gt;If you are working with text at scale, I recommend you pay for one of the many wonderful...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;So you&amp;rsquo;ve got some audio that you want to turn into text? There are a lot of good, inexpensive options out there powered by machines, people, and a mix of the two. &lt;/p&gt;

&lt;p&gt;If you are working with text at scale, I recommend you pay for one of the many wonderful services or pay to have someone integrate machine-learning-powered speech-to-text with your workflows.&lt;/p&gt;

&lt;p&gt;However, if you&amp;rsquo;re just looking to transcribe an interview for something like a case study, testimonial, or qualitative feedback, you don&amp;rsquo;t have the budget to pass off this tedious work to someone else, and don&amp;rsquo;t have the patience to do everything yourself then this hacked together workflow will speed up the boring bits significantly.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m going to show you how to use IBM Watson&amp;rsquo;s Speech-to-Text along with Python in order to partially automate the transcription process. IBM allows 100  minutes of transcription a month which should be enough most people who need a hacky solution like this.&lt;/p&gt;

&lt;p&gt;Machine transcription is far from perfect, and IBM Watson is no exception. You&amp;rsquo;ll need to read the output while listening along and check the words as well as add punctuation, but I&amp;rsquo;d estimate that I can do five minutes of audio in about 15 minutes of work now that I have this set up whereas it could take the better part of an hour before.&lt;/p&gt;

&lt;h2&gt;Dev Environment&lt;/h2&gt;

&lt;p&gt;You&amp;rsquo;ll need to be able to run Python in order to follow the instructions here. If you&amp;rsquo;re on Mac or Linux, you&amp;rsquo;ve already got Python installed and should be good to go.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re on a Windows machine, then you have some work to do &lt;a href="https://docs.python.org/3.3/using/windows.html"&gt;installing Python on Windows&lt;/a&gt;, &lt;a href="https://www.cygwin.com/"&gt;Cygwin&lt;/a&gt;, or setting up the &lt;a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10"&gt;Windows Subsystem for Linux (WSL)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In my case, I&amp;rsquo;ve got WSL running Ubuntu Linux in Visual Studio Code. I installed Bash, integrated it with VS Code and then followed the Linux instructions to get Python running.&lt;/p&gt;

&lt;p&gt;Setting this up is way beyond the scope of this article. It took me a lot of Googling but I&amp;rsquo;m sure you&amp;rsquo;ll get there if you have enough time.&lt;/p&gt;

&lt;p&gt;Alternately, ask a Mac-using friend to borrow their computer.&lt;/p&gt;

&lt;h2&gt;Sign Up for Watson&lt;/h2&gt;

&lt;p&gt;First, &lt;a href="https://console.bluemix.net/registration/"&gt;create an IBM Cloud account&lt;/a&gt; and confirm your email, agree to give up your next child in the TOS, and finish all of the usual other setup steps.&lt;/p&gt;

&lt;p&gt;Next, go to your IBM &lt;a href="https://console.bluemix.net/registration/"&gt;Bluemix Console&lt;/a&gt; (log in if you need) and then search for and select &amp;ldquo;speech to text&amp;rdquo;. The defaults should be fine for a hacked together tool like this.&lt;/p&gt;

&lt;p&gt;You should be on a page listing your speech-to-text settings. We&amp;rsquo;re interested in two things. Your API Key (keep this secret) and the Url where IBM is listening for your requests.&lt;/p&gt;

&lt;p&gt;&lt;img src="speech-to-text/watson-speech-to-text.png" title="Watson speech-to-text configuration information" alt="Watson speech-to-text configuration information" /&gt;&lt;/p&gt;

&lt;p&gt;We will need both of these things when setting up your scripts.&lt;/p&gt;

&lt;h2&gt;Set Up Your Scripts&lt;/h2&gt;

&lt;p&gt;With Python, hopefully, up and running and your IBM account you&amp;rsquo;re ready to set things up.&lt;/p&gt;

&lt;p&gt;First, create a folder to host your scripts.  We&amp;rsquo;re going to save the input audio here and have a text file to receive the output text along with the command line commands and Python scripts that do all of the work.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;ve already got a dev environment set up, then you know where you want to put this. &lt;/p&gt;

&lt;p&gt;Otherwise, I recommend creating a dev folder under your user and under that add utils and speech-to-text subfolders.&lt;/p&gt;

&lt;p&gt;Now it&amp;rsquo;s time to get the files set up. You can download them or &lt;a href="https://github.com/dgitis/speech-to-text"&gt;clone them from GitHub here&lt;/a&gt; or follow along and add them as we go.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;First, open or create a file called console.txt&lt;/strong&gt;. This holds the command line script that you&amp;rsquo;re going to run.&lt;/p&gt;

&lt;script src="https://gist.github.com/dgitis/2af0e563abb90f554c7738c9eed8eb3b.js"&gt;&lt;/script&gt;

&lt;p&gt;What these lines do, when entered in your terminal, is tell your computer to send an audio file named &lt;em&gt;input.flac&lt;/em&gt; to IBM&amp;rsquo;s server authenticated with your API key, return the audio as text and put it in a file called &lt;em&gt;watson.json&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Remember the API key and URL from your IBM Bluemix console that I asked you to remember? You&amp;rsquo;re going to put them in here.&lt;/p&gt;

&lt;p&gt;The API key goes in the place helpfully marked &amp;ldquo;your&lt;em&gt;api&lt;/em&gt;key&amp;rdquo; in the first line.&lt;/p&gt;

&lt;p&gt;If you kept the default region (Dallas) in setup, then you don&amp;rsquo;t need to change the URL. Otherwise, you&amp;rsquo;ll want to replace everything from _https _to _api _in the URL on the fourth line with the URL from the console.&lt;/p&gt;

&lt;p&gt;Otherwise we&amp;rsquo;re good here.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Next, open or create a file called &lt;em&gt;json-to-text.py&lt;/em&gt;&lt;/strong&gt;. This file is going to parse the JSON from IBM in the &lt;em&gt;watson.json&lt;/em&gt; file and write it to a file containing raw text named &lt;em&gt;formatted&lt;/em&gt;text.txt_.&lt;/p&gt;

&lt;script src="https://gist.github.com/dgitis/12a99cd1e38764825db1ffa323768fbc.js"&gt;&lt;/script&gt;

&lt;p&gt;We don&amp;rsquo;t actually need to do anything with this other than to save it.&lt;/p&gt;

&lt;h2&gt;Running the Script&lt;/h2&gt;

&lt;p&gt;The eagle-eyed among you will have noticed that the audio file that we&amp;rsquo;re working with is called &lt;em&gt;input.flac&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;If you can capture your audio in flac format, then do so because you&amp;rsquo;ll get much better results. In this case, name the file input.flac and place it in the speech-to-text folder where you installed the other files.&lt;/p&gt;

&lt;p&gt;Otherwise, you&amp;rsquo;re going to need to convert your audio to flac format before renaming and and putting it in the correct folder. At the time of writing, &lt;a href="https://audio.online-convert.com/convert-to-flac"&gt;this service is free&lt;/a&gt; but there are plenty of other ways that you can do this.&lt;/p&gt;

&lt;p&gt;Now, open up your Terminal application. Windows users running Linux on Windows will want to open the Linux Terminal and change directory to your speech-to-text folder.&lt;/p&gt;

&lt;aside class="panel"&gt;
&lt;h3&gt;Navigating the Terminal&lt;/h3&gt;

&lt;p&gt;Typing _ls_ in the command line shows all of the files and folders in your current directory.&lt;/p&gt;

&lt;p&gt;Typing _cd directory_name_ moves into a folder in your current directory.&lt;/p&gt;

&lt;p&gt;Typing _cd .._ moves back up a step.&lt;/p&gt;

&lt;p&gt;Keep using the cd (and ls if you need to orient yourself) command to navigate your way to your speech-to-text folder.&lt;/p&gt;

![command prompt](/blog/speech-to-text/command-prompt.png &amp;ldquo;command prompt&amp;rdquo;)

&lt;p&gt;You can see your progress as you cd up and down in the command prompt (shown in blue in the above screenshot) left of the dollar signs.&lt;/p&gt;
&lt;/aside&gt;

&lt;p&gt;Once you&amp;rsquo;re in right folder, copy and paste the contents of console.txt (with your API key and updated URL if necessary) into the terminal.&lt;/p&gt;

&lt;p&gt;&lt;img src="speech-to-text/watson-speech-to-text-at-work.png" title="Watson speech-to-text at work" alt="Watson speech-to-text at work" /&gt;&lt;/p&gt;

&lt;p&gt;This will take some time depending on how much audio you&amp;rsquo;re transcribing. The file I used took about one minute to transcribe one minute of audio so maybe it goes through it without fast forwarding or separating the file into chunks for parallel processing.&lt;/p&gt;

&lt;p&gt;I usually like to take advantage of moments like this by being conspicuously idle encouraging coworkers and bosses to comment so I can respond &amp;ldquo;I&amp;rsquo;m transcribing audio as we speak. What are you doing?&amp;rdquo; It&amp;rsquo;s great for morale (well, yours at least).&lt;/p&gt;

&lt;p&gt;When it&amp;rsquo;s done you should have a long JSON file that doesn&amp;rsquo;t look anything like the words you&amp;rsquo;re transcribing.&lt;/p&gt;

&lt;p&gt;That little &lt;em&gt;json-to-text.py&lt;/em&gt; file that we created earlier will fix this.&lt;/p&gt;

&lt;p&gt;In your terminal, type python json-to-text.py and you should have your transcription in the formatted_text.txt file almost immediately. The terminal doesn&amp;rsquo;t even bother to tell you its done.&lt;/p&gt;

&lt;p&gt;&lt;img src="speech-to-text/json-to-text.png" title="JSON to text command" alt="JSON to text command" /&gt;&lt;/p&gt;

&lt;p&gt;Go check formatted_text.txt where you&amp;rsquo;ll see your transcription in all its highly-in-need-of-editing glory.&lt;/p&gt;

&lt;p&gt;Discuss on &lt;a href="https://www.linkedin.com/feed/update/urn:li:activity:6470706540327235584"&gt;LinkedIn&lt;/a&gt; or &lt;a href="https://github.com/dgitis/speech-to-text"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Are you data driven? Or just numbers driven?</title>
    <link rel="alternate" href="https://www.caretjuice.com/blog/data-driven.html"/>
    <id>https://www.caretjuice.com/blog/data-driven.html</id>
    <published>2018-02-28T16:00:00-08:00</published>
    <updated>2018-11-14T11:36:14-08:00</updated>
    <author>
      <name>Damon Gudaitis</name>
    </author>
    <summary type="html">&lt;p&gt;Data is important to modern marketing.&lt;/p&gt;

&lt;p&gt;When young marketing professionals ask what they should learn to get ahead, you are almost certain to hear data literacy as core skill for advancement.&lt;/p&gt;

&lt;p&gt;The Chief Martech &lt;a href="http://chiefmartec.com/2017/05/marketing-techniology-landscape-supergraphic-2017/"&gt;2017 Marketing Technology Landscape&lt;/a&gt; has...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;Data is important to modern marketing.&lt;/p&gt;

&lt;p&gt;When young marketing professionals ask what they should learn to get ahead, you are almost certain to hear data literacy as core skill for advancement.&lt;/p&gt;

&lt;p&gt;The Chief Martech &lt;a href="http://chiefmartec.com/2017/05/marketing-techniology-landscape-supergraphic-2017/"&gt;2017 Marketing Technology Landscape&lt;/a&gt; has over 5000 companies listed—up from 150 in just 2011. All of those add or use data in some way.&lt;/p&gt;

&lt;p&gt;Google Trends shows a steady increase in interest in &amp;ldquo;data-driven marketing&amp;rdquo; over the past decade. The spikes in interest just before the decade look like special cause problems in the data collection—the alternating months of zero interest with interest almost on par with today is what makes those numbers suspect.&lt;/p&gt;

&lt;p&gt;&lt;img src="/blog/data-driven/data-driven-marketing-trends.png" alt="google trends for data driven marketing"&gt;&lt;/p&gt;

&lt;p&gt;All of this is to say that data is important to marketing today.&lt;/p&gt;

&lt;h2&gt;What if we&amp;rsquo;re not data driven, but numbers driven?&lt;/h2&gt;

&lt;p&gt;When we talk about data, we usually talk about numbers, but it&amp;rsquo;s important to remember that data does not equal numbers.&lt;/p&gt;

&lt;p&gt;We have quantitative and qualitative data: numbers and text (or audio, or qualitative numbers).&lt;/p&gt;

&lt;p&gt;Qualitative data, when applied to marketing, includes things like open-ended surveys and all sorts of text and audio data generated during phone calls.&lt;/p&gt;

&lt;p&gt;When a marketing leader boasts about being data driven, are they including interviews and open-ended surveys? Usually, the answer is no.&lt;/p&gt;

&lt;p&gt;They are numbers driven. They want to maximize revenue and minimize expenses and use a lot of intermediary marketing metrics to get there on the way.&lt;/p&gt;

&lt;p&gt;This might be a safe way to manage marketing, but it&amp;rsquo;s not the best.&lt;/p&gt;

&lt;h2&gt;What if being numbers driven is bad?&lt;/h2&gt;

&lt;p&gt;The most important equation to any business is this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Profit = Revenue - Expenses&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You don&amp;rsquo;t need to make a profit every quarter, or even every decade (just ask Amazon). But you need to understand this equation to plan for future success.&lt;/p&gt;

&lt;p&gt;Optimizing for the numbers isn&amp;rsquo;t likely result in a healthy business whether you are optimizing for P = R - E or for leads, marketing qualified leads, or opportunities.&lt;/p&gt;

&lt;p&gt;Controversial?&lt;/p&gt;

&lt;p&gt;Superficially, yes. But it&amp;rsquo;s the logical conclusion of lessons most marketers have already internalized.&lt;/p&gt;

&lt;p&gt;Say, for example, a SaaS company wants to minimize expenses. They can halve the headcount of the support department and instantly reduce expenses and increase profit. The executives can pay themselves bonuses and happily move on to their next brilliant plan.&lt;/p&gt;

&lt;p&gt;However, the newly downsized support department can&amp;rsquo;t keep up with demand for support.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;  Tickets now take longer to be resolved. &lt;/li&gt;
&lt;li&gt;  Some of your customers grow unhappy. &lt;/li&gt;
&lt;li&gt;  Some costly problems fester unsolved. &lt;/li&gt;
&lt;li&gt;  Morale in the support department crashes which further undermines service.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The end result is that customers start to churn (or they share their experiences with their peers and you lose out on deals without measuring or knowing it).&lt;/p&gt;

&lt;p&gt;By optimizing for numbers you&amp;rsquo;ve undercut the business. And you&amp;rsquo;ve done so in a way that results in short-term executive rewards. But the end result is lower revenue and profit.&lt;/p&gt;

&lt;p&gt;The point of this example isn&amp;rsquo;t to say that numbers are bad or that you can&amp;rsquo;t use numbers.&lt;/p&gt;

&lt;p&gt;It is to remind you that numbers are abstractions of reality.&lt;/p&gt;

&lt;p&gt;You could very easily look at the P = R - C equation and decide to analyze support requests and change your product or site to reduce the number of support calls that are made and achieve cost savings the same way.&lt;/p&gt;

&lt;p&gt;Conversely, you can come up with much less obviously bad examples where, for example, you increase short-term sales in a way that causes support to suffer, craters your reputation and reduces long-term revenue.&lt;/p&gt;

&lt;p&gt;P = R - C correlates perfectly with profit. But it does not cause profit.&lt;/p&gt;

&lt;p&gt;Your leads, marketing qualified leads, and opportunities are even more poorly correlated with profit. Making numbers-driven decisions to optimize for any of these things is even more dangerous.&lt;/p&gt;

&lt;p&gt;KPIs are abstractions. They are correlated with business success. But they don&amp;rsquo;t cause that success.&lt;/p&gt;

&lt;h2&gt;The Repeated, Colossal Failure of Marketing Data&lt;/h2&gt;

&lt;p&gt;Numbers-driven marketing is responsible for ruining marketing. And we do it over and over again without learning.&lt;/p&gt;

&lt;p&gt;Banner ads used to actually work. What made them drop to a 0.03 percent average click-thru rate (most of which are bots or accidental clicks because how often do you actually click on ads)?&lt;/p&gt;

&lt;p&gt;We optimized for numbers rather than for the experience. Instead of trying to create ads that drew the right people in, we made ads flashier and more garish relevance-be-damned.&lt;/p&gt;

&lt;p&gt;People learned and stopped paying attention. We kept optimizing our conversion rates down hundredths of a percent.&lt;/p&gt;

&lt;p&gt;New, personalized video tactics being used in ABM will no doubt go the same way. Writing someone&amp;rsquo;s name on a handheld whiteboard is going to get attention and get your pitch heard.&lt;/p&gt;

&lt;p&gt;Personalized video vendors will start sharing how following these personalized video best-practices improve metrics. Everyone will jump in with canned pitches that don&amp;rsquo;t reflect the extra level of care that these tactics originally embodied and we&amp;rsquo;ll optimize those videos out of relevance.&lt;/p&gt;

&lt;h2&gt;Plato, the Allegory of the Cave, and Data-Driven Marketing&lt;/h2&gt;

&lt;p&gt;Plato&amp;rsquo;s Allegory of the Cave is the classical illustration of the problem with treating abstractions of reality as if they are real. (I&amp;rsquo;ll admit that Plato&amp;rsquo;s idea of forms is different, but that doesn&amp;rsquo;t make the allegory any less poignant.)&lt;/p&gt;

&lt;p&gt;In The Allegory of the Cave, in case you need a refresher, there are a row of people staring at the wall of a cave. Behind them is a fire and some puppets projecting shadows on the wall.&lt;/p&gt;

&lt;p&gt;The people staring at the wall see the shadows and believe that to be reality. They even talk amongst themselves and reinforce their belief that the shadow is reality.&lt;/p&gt;

&lt;p&gt;The shadows are the numbers used in numbers-driven marketing absent any context from qualitative data. They are representations of reality.&lt;/p&gt;

&lt;p&gt;The people interacting with your marketing are the reality that produce those numbers.&lt;/p&gt;

&lt;p&gt;Why would you base decisions strictly off of representations when it is easy to give those numbers meaning by turning away from that wall and looking at what causes shadows?&lt;/p&gt;

&lt;p&gt;Talking to your sales and customer service reps isn&amp;rsquo;t enough. They are dealing with a different set of people.&lt;/p&gt;

&lt;p&gt;Early- and mid-career professionals frequently ignite sales cycles internally without ever appearing on the buying committee that speaks with sales.&lt;/p&gt;

&lt;p&gt;The main technology users that customer service reps meet are rarely more than a fraction of the buying committee.&lt;/p&gt;

&lt;p&gt;Data from sales and customer service reps is better than nothing, but it doesn&amp;rsquo;t compare with qualitative data gained through direct contact with the people in your funnels.&lt;/p&gt;

&lt;h2&gt;Qualitative Context Gives Number Meaning&lt;/h2&gt;

&lt;p&gt;Interviewing leads at various stages of your funnel provides the context that gives all of your numbers meaning.&lt;/p&gt;

&lt;p&gt;Increasing your lead to marketing qualified lead conversion rate won&amp;rsquo;t necessarily increase revenue. You might just end up sending more bad leads to sales and waste more time.&lt;/p&gt;

&lt;p&gt;Pairing qualitative data on what motivates your leads and what needs or doubts that they have gives you the context to create better experiences and know that your improved metrics represent real improvements to the experience of becoming a customer and not just shadows without concrete meaning.&lt;/p&gt;

&lt;p&gt;The best thing about qualitative data is that you don&amp;rsquo;t need a lot of it for it to be useful. Each interview will return many insights which you can then use to run A/B tests and quantify the improvement all while knowing that the lift in conversion rate is actually related to causing downstream revenue improvements.&lt;/p&gt;

&lt;p&gt;Without qualitative context, quantitative data has no value.&lt;/p&gt;

&lt;h2&gt;Going from Numbers Driven to Data Driven&lt;/h2&gt;

&lt;p&gt;There is a lot of value in the numbers that marketing generates, but to fully take advantage of that value you need to understand the context in which numbers occur.&lt;/p&gt;

&lt;p&gt;The good news is that these ideas I&amp;rsquo;ve presented here aren&amp;rsquo;t in any way new and they certainly aren&amp;rsquo;t mine. They are built on product management practices tested by companies like Intercom and Basecamp which are in turn built on manufacturing practices that have been around since the end of the Second World War.&lt;/p&gt;

&lt;p&gt;And because others have blazed the trail, we can learn and build from their experiences.&lt;/p&gt;

&lt;p&gt;Jobs-to-be-Done thinking provides some ideas for getting past the superficial needs to understand the motivations. What job is are people hiring my product for? JTBD theory was conceived to engineer and market innovative products and services that people want without falling into the trap of delivering what they think they want.&lt;/p&gt;

&lt;p&gt;Why can&amp;rsquo;t we apply it to our marketing funnels? What jobs do people hire your webinars to do? Your demos? Your free trials?&lt;/p&gt;

&lt;p&gt;An important part of JTBD theory is figuring out what causes people to fire their current solution. &lt;/p&gt;

&lt;p&gt;Another one is figuring out what job comes next after they&amp;rsquo;ve hired a solution.&lt;/p&gt;

&lt;p&gt;These are fundamental problems facing enterprise marketers and JTBD theory provides ideas for using qualitative data to understand and overcome them.&lt;/p&gt;

&lt;p&gt;JTBD theory is based on Systems Thinking.&lt;/p&gt;

&lt;p&gt;Systems Thinking is credited for the post WWII renaissance of Japanese manufacturing (and its originator, W. Edwards Deming, predicted its downfall when the Japanese started sending their brightest to get MBAs in the West).&lt;/p&gt;

&lt;p&gt;Lean manufacturing, Kanban, Six Sigma are some of its direct offspring which means that it can also share a claim of ancestry for agile software development.&lt;/p&gt;

&lt;p&gt;How might enterprise marketers, who have to sell to multiple buyers with multiple influencers going through long, drawn out buying processes apply a way of looking at management (and the world) that embraces the interdependencies within systems?&lt;/p&gt;

&lt;p&gt;We have buyer personas and funnels. But how well do we understand the relationships between personas and business processes? How well do we understand how change affects those relationships? And how well do your funnels represent reality?&lt;/p&gt;

&lt;p&gt;Systems Thinking provides ideas for understanding interdependencies so that we can better structure our own marketing systems and understand how to influence the corporate social ecosystem.&lt;/p&gt;

&lt;h2&gt;Atomic or Ecological&lt;/h2&gt;

&lt;p&gt;Business thought is divided between the atomic view, where every division is a cog in the machine and every person in the division is another cog within that greater part, and the ecological view, where affecting one part of the system can have many, unpredictable effects on other parts.&lt;/p&gt;

&lt;p&gt;A numbers-driven approach to marketing is within the atomic view. A whole data approach that includes qualitative context is within the ecological view.&lt;/p&gt;

&lt;p&gt;Systems Thinking is the most influential ecological view of business management and Jobs-to-be-Done thinking is an application of Systems Thinking to product management and product marketing.&lt;/p&gt;

&lt;p&gt;Design Thinking is a recent ecological response to the problems of atomized design that also provides plenty more ideas that we could use to design enterprise marketing experiences.&lt;/p&gt;

&lt;p&gt;The Internet has primed buyers to expect ecological experiences when they buy but enterprise marketers are still struggling to adapt relying on models adapted from consumer marketing.&lt;/p&gt;

&lt;p&gt;All of these disciplines are great sources of ideas for making your marketing more data driven and less numbers driven.&lt;/p&gt;

&lt;p&gt;If you need some help getting started or you&amp;rsquo;re overwhelmed, Caret Juice Marketing offers a guaranteed interview and insights package to help you get started with data-driven marketing in a way that limits risk and commitment. We narrowly apply these ideas by interviewing 10 people who completed a recent conversion event and then report on the insights from those interviews.&lt;/p&gt;

&lt;p&gt;You can then decide whether the insights are worth it and decide whether to pay and continue working with Caret Juice.&lt;/p&gt;

&lt;p&gt;&lt;a href="/contact.html"&gt;Contact us to get started&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>The Role of Testing in B-to-B Marketing</title>
    <link rel="alternate" href="https://www.caretjuice.com/blog/testing-role-b-to-b.html"/>
    <id>https://www.caretjuice.com/blog/testing-role-b-to-b.html</id>
    <published>2017-04-05T17:00:00-07:00</published>
    <updated>2018-11-13T14:24:11-08:00</updated>
    <author>
      <name>Damon Gudaitis</name>
    </author>
    <summary type="html">&lt;p&gt;Each little interaction in B-to-B marketing is a promise that the company makes to the prospective buyer. Every promise that is fulfilled builds trust with an individual and across an organization.&lt;/p&gt;

&lt;p&gt;The role of marketing in B-to-B is to build incremental...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;Each little interaction in B-to-B marketing is a promise that the company makes to the prospective buyer. Every promise that is fulfilled builds trust with an individual and across an organization.&lt;/p&gt;

&lt;p&gt;The role of marketing in B-to-B is to build incremental trust ahead of and during a sales cycle by keeping promises:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The snippet in the search results is a promise that your product (or podcast, or blog post) will help the buyer answer the problem that initiated the search.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The email notification that you published a new blog post is a promise that reading will be worth the buyer’s time.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The copy on a webinar landing page is a promise that the buyer will learn something worth sacrificing an hour of their time.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The individual fields in your request a demo form are promises that you will use that information to give the buyer a better demo.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The role of testing is to make sure that you are making the right promises. Testing anything less ambitious is setting your B-to-B program up for failure. Failure is a big danger since all you need to do is follow the best-practice advice of ecommerce conversion rate optimization.&lt;/p&gt;

&lt;p&gt;The design of your test program will make the difference between success and failure with A/B testing. But the testing role in B-to-B shouldn’t be limited to A/B testing in the browser. Qualitative feedback and strategic A/B testing are tactics that can multiply the impact of your B-to-B testing program.&lt;/p&gt;

&lt;h2&gt;A/B Testing&lt;/h2&gt;

&lt;p&gt;A/B testing in B-to-B environments is a challenge:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You have lower traffic so it takes longer to get a significant result.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The final conversion doesn’t happen on your website.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The final conversion occurs several months after the first interaction with your website so it is hard to tell whether a conversion early in the buyer’s journey has an effect on later sales.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You can have several people involved in the final conversion who interact with online and offline sales and marketing in a variety of ways.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Despite these many challenges you can build a testing program that uses A/B testing to powerful effect through good program design.&lt;/p&gt;

&lt;h3&gt;Simplicity&lt;/h3&gt;

&lt;p&gt;You will have to compensate for the complexity of your conversion with simplicity in your testing program.&lt;/p&gt;

&lt;p&gt;The first rule for B-to-B testing is to stick to A/B testing. Multivariate testing looks awesome in theory, but it will take 20 years to get a significant result at B-to-B traffic level. &lt;/p&gt;

&lt;p&gt;Even when you get a significant result, you are still just testing for the conversion that you can see rather than the actual revenue conversion.&lt;/p&gt;

&lt;p&gt;Keep it simple and get quick results so you can book improvements and launch new tests soon after.&lt;/p&gt;

&lt;h3&gt;Test Your Fundamental Assumptions About the Customer&lt;/h3&gt;

&lt;p&gt;Testing the fundamentals is an important corollary to keeping your testing program simple.&lt;/p&gt;

&lt;p&gt;The button-color warriors of ecommerce testing can get away with testing every minute detail because tiny lifts in conversion can result in immediate lifts in revenue that have a material impact.&lt;/p&gt;

&lt;p&gt;In B-to-B testing, it will take 10 years to get a significant result if you’re going after 0.2 percent lift. The obvious solution to this problem is to test the big stuff.&lt;/p&gt;

&lt;p&gt;Are your prospects better motivated by avoiding pain? Or by the recognition they’ll get if your solution makes them a success?&lt;/p&gt;

&lt;p&gt;Are your prospects better motivated by the contents of the webinar? Or the outcomes of the webinar?&lt;/p&gt;

&lt;p&gt;Test your underlying assumptions and target gains of 20 percent, 50 percent, or more. And, in doing so, you should expect significant results in about a month.&lt;/p&gt;

&lt;p&gt;You will know that you are doing this right if you are learning lessons about your customers that don’t just help you convert them at each micro-conversion of the buying journey, but also help you better communicate with the buyer throughout the journey.&lt;/p&gt;

&lt;h3&gt;Collect Assumptions&lt;/h3&gt;

&lt;p&gt;In order to challenge your assumptions, you’re going to need to know what those assumptions were.&lt;/p&gt;

&lt;p&gt;An outsider’s perspective is valuable because the outsider can challenge assumptions that the people involved in producing an individual piece of marketing collateral may have missed.&lt;/p&gt;

&lt;p&gt;However, as an outsider you’ll very quickly find the patterns that give big gains when you test. By all means keep testing these patterns, but your testing program will stagnate if you rely on just the patterns that you know work well.&lt;/p&gt;

&lt;p&gt;The individuals involved in the original production should also have a deep understanding of what thoughts, disagreements, and compromises went in to the content. These people too are a valuable source of assumptions that you can test.&lt;/p&gt;

&lt;p&gt;If you are the outsider running tests, then you want the whole sales and marketing team to know that you want to test assumptions and you should make it easy for them to communicate what assumptions and compromises that they made to complete the content.&lt;/p&gt;

&lt;h3&gt;Choosing What Assumptions to Test First&lt;/h3&gt;

&lt;p&gt;With feedback coming from throughout the marketing department, you’ll want a fair and transparent way to set priorities. Anything less and you run the risk of turning others off of your testing program and losing their contributions.&lt;/p&gt;

&lt;p&gt;While you can’t A/B test easily against sales, you can test against each promise—each micro-conversion. And with clear funnel definitions, you can use historical data to calculate the value of each micro-conversion.&lt;/p&gt;

&lt;p&gt;With the value of a micro-conversion, a testable hypothesis, a little bit of analytics data, and an estimate for the lift you expect from the test, you can do a quick &lt;em&gt;pro-forma&lt;/em&gt; analysis to calculate the expected revenue impact of each test.&lt;/p&gt;

&lt;p&gt;While this can be manipulated by biasing your estimates, even a flawed, good-faith estimating process can help you pick the best tests first while giving others transparency into the testing process.&lt;/p&gt;

&lt;h3&gt;Share Your Lessons&lt;/h3&gt;

&lt;p&gt;The goal of a B-to-B testing program should be to better understand your buyers rather than just improving conversion rates.&lt;/p&gt;

&lt;p&gt;You need to test assumptions in order to get results that are big enough that your tests achieve an acceptable sample size in a reasonable amount of time. But you should also be making valuable discoveries about your buyers.&lt;/p&gt;

&lt;p&gt;A B-level testing program helps the testers better understand your buyers. An A-level testing program helps the entire team better understand your buyers.&lt;/p&gt;

&lt;p&gt;Using the whole team to source test ideas can help get the team invested in your testing program. Sharing the lessons learned from your best tests both serves to show the value of their feedback, but also helps deepen the team’s understanding of your buyers.&lt;/p&gt;

&lt;h3&gt;Micro-Conversions&lt;/h3&gt;

&lt;p&gt;Each promise in the buyer’s journey is a micro-conversion and each micro-conversion can be tested.&lt;/p&gt;

&lt;p&gt;Any decently valuable solution that you sell is going to be costly and the buying decision is going to be complex. You don’t want to wait for a nine-month buying cycle to come to the end before evaluating your first tests.&lt;/p&gt;

&lt;p&gt;That’s why you need to test against micro-conversions and optimize against each step in the path.&lt;/p&gt;

&lt;p&gt;You can’t take the results of these tests to your CFO, say &amp;ldquo;webinar sign-ups are up by 30 percent,&amp;rdquo; and expect to get a big bump in the marketing budget. But you can turn around tests a lot more quickly. &lt;/p&gt;

&lt;p&gt;The results of these tests may be a little dubious since they aren’t tested against revenue, but they will let you complete more tests and make more micro-improvements up the funnel that will cumulatively be better than waiting for the bottom-line results.&lt;/p&gt;

&lt;p&gt;You won’t know whether each test increases sales when you get your initial results, but you can run a retrospective analysis after a couple of sales cycles to check whether micro-conversions are having the expected impact.&lt;/p&gt;

&lt;h3&gt;The Funnel&lt;/h3&gt;

&lt;p&gt;One key to a strengthening your testing program is to have a well-defined funnel that reflects how buyers develop into customers. The funnel will help you estimate and measure the impact of each test.&lt;/p&gt;

&lt;p&gt;Estimating the value of a conversion is a challenge when each conversion lives in isolation. In reality, they are part of a system for building trust, educating the buyer, and making a sale.&lt;/p&gt;

&lt;p&gt;By categorizing each conversion by funnel stage, you can more finely tune the values without expensive multi-touch conversion modelling.&lt;/p&gt;

&lt;p&gt;Someone following you on Twitter or LinkedIn, or signing up for blog updates doesn’t have the same value as someone who has done all of those things and has started to learn about your product. And they have even less value than someone who is calculating the ROI of your solution.&lt;/p&gt;

&lt;p&gt;By having a clear funnel, you can assign values to each stage in the funnel rather than each conversion. Assigning value to stages better reflects the actual value of a conversion compared with weighting all conversions equally and it takes alot less effort and expense than multi-touch.&lt;/p&gt;

&lt;p&gt;With a strong funnel definition in place and a strong understanding of the value at each stage, you can better estimate the value of a test without much change to your marketing stack. Testing this way can also help you better understand and refine your funnel.&lt;/p&gt;

&lt;h3&gt;Retrospective Analysis&lt;/h3&gt;

&lt;p&gt;Running one test against bottom-line revenue takes too long to be worthwhile when compared against running lots of tests against micro-conversions. But that doesn’t mean that you can’t try to catch results that produce positive micro-conversions but negative revenue.&lt;/p&gt;

&lt;p&gt;Once you’ve been running tests long enough to have prospects who’ve been through tested assets and turned into customers, you should look at your conversion data, calculate the expected revenue lift for the improved conversion rate, and compare that with the actual lift.&lt;/p&gt;

&lt;p&gt;The data will be messy and you won’t catch every bad result.&lt;/p&gt;

&lt;p&gt;But if you’re testing important assumptions, periodically looking at data will let you catch tests that badly underperform in terms of revenue. This in turn should give you ideas for what assumptions that need to be challenged.&lt;/p&gt;

&lt;h3&gt;Isolating Tests in B-to-B Testing Programs&lt;/h3&gt;

&lt;p&gt;If you’re testing assumptions, as I recommend, then you’re going to run into challenges isolating your test.&lt;/p&gt;

&lt;p&gt;If you want to test, for example, different assumptions about why buyers sign up for webinars and all of your assets (ads, social media posts, calls to action, and landing page) support the initial assumption, then you can’t just run a test swapping out copy on the landing page.&lt;/p&gt;

&lt;p&gt;Your challenge may be correct, but the promises you made to get the click to the landing page won’t align with the challenger version on the landing page. You’ll need to watch for this sort of co-dependency and then create alternate ads, social media posts, and CTAs that align with the message you are testing and send these alternates to the challenger landing page.&lt;/p&gt;

&lt;p&gt;Not every test will suffer from this form of co-dependency, but you will need to watch for it.&lt;/p&gt;

&lt;p&gt;Isolating tests is also important when dealing with tests on pages or resources that occur close together on the conversion path.&lt;/p&gt;

&lt;p&gt;For example, you can’t test your home page messaging and your product page messaging at the same time since a significant proportion of your product page visits will pass through the home page. The results are co-dependant and running co-dependant tests together will mess up your sampling and results.&lt;/p&gt;

&lt;h3&gt;The A/B Testing Wall&lt;/h3&gt;

&lt;p&gt;If you follow the above outline for a testing program, you should have a steady source of good testing ideas but nothing is going to stop you from hitting a wall in your A/B testing program where results start coming slower and you find yourself with too much time between tests.&lt;/p&gt;

&lt;p&gt;This is because early on in your testing program the opportunity is great. Increasing your conversion rate from three percent to six percent is much easier than six to 12.&lt;/p&gt;

&lt;p&gt;At some point you will run close to the limits of optimization where the only way you can get big lifts in conversion rate is to confuse people who have no business converting. This is deadly where your conversions don’t result in immediate revenue and short-sighted under any circumstances.&lt;/p&gt;

&lt;p&gt;Meanwhile, your best tests, in terms of quality, will still only give a lift of a few tenths of a percent and you’ll be back to six months plus to get a significant result.&lt;/p&gt;

&lt;p&gt;If the team is learning about your buyers from your tests, then you can expect that new marketing assets will already start at a higher level than when you started the testing program so your new testing opportunities shouldn’t be as good as your original ones.&lt;/p&gt;

&lt;p&gt;Additionally, each test can affect the results of another so you need to be careful about running too many tests at once.&lt;/p&gt;

&lt;p&gt;If you want to test your home page’s ability to identify new opportunities, you can’t also test your product pages’ ability to convert those opportunities. The tests are co-dependant and should not be run in parallel.&lt;/p&gt;

&lt;p&gt;As a result, you will find rapidly diminishing returns and a whole lot of free time as your A/B testing program matures. And, while you shouldn’t abandon A/B testing, you will make yourself dead weight on the team if you limit yourself to A/B testing in the browser.&lt;/p&gt;

&lt;h2&gt;Beyond A/B Testing&lt;/h2&gt;

&lt;p&gt;While A/B testing in a B-to-B setting can be valuable if done right, you will limit your results if you stick to the popular testing tools and built-in testing functions of your ad and marketing automation platforms.&lt;/p&gt;

&lt;p&gt;Qualitative feedback and strategic A/B testing are two techniques that go beyond your standard testing tools. They can be the source of valuable lessons and results while extending the influence of testing beyond the browser.&lt;/p&gt;

&lt;h3&gt;Qualitative Feedback&lt;/h3&gt;

&lt;p&gt;B-to-B marketers are forced to make a lot of assumptions about their buyers.&lt;/p&gt;

&lt;p&gt;We have tools like personas, case studies, and marketing funnels to help standardize lessons across the marketing team. We can use A/B testing or sit in on sales calls to challenge our assumptions, but there’s still a lot of guess work involved.&lt;/p&gt;

&lt;p&gt;Qualitative feedback, a fancy term for listening, helps challenge those assumptions and get results faster than a stand-alone A/B test.&lt;/p&gt;

&lt;p&gt;If you want to get a better understanding of what your buyers are thinking at various points in their journey, then you should contact them during their journey and listen.&lt;/p&gt;

&lt;p&gt;The goals for qualitative feedback can vary from broad understanding, like what the buyer is thinking at different stages of the funnel, to narrow understanding, like what did they want from a specific webinar.&lt;/p&gt;

&lt;p&gt;While the questions you ask will depend on your goals, the following survey questions are a good start for capturing what’s important to the buyer without taking too much time.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What were you trying to accomplish?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Did you accomplish it?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How can we do better?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition, there’s a fourth question that you should be able to infer from these answers that you can use to evaluate your lead scoring.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Are you in a buying cycle?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By recording the answer to this fourth question, you can evaluate whether your lead scoring is letting leads who should go to sales slip by and calculate the missed opportunity.&lt;/p&gt;

&lt;p&gt;While there are tools that automate feedback, I think picking up the phone and calling leads who are in the midst of their buyer&amp;rsquo;s journey, asking the questions, and listening is worth the effort.&lt;/p&gt;

&lt;p&gt;By using automated tools, like feedback popups embedded on your site, you are limiting the effectiveness of your survey.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You are biasing your responses to only those who are willing to fill out the form which will skew your data and hurt your analysis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You are annoying your visitors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Your responses will be more filtered as people edit their writing better than their speech.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You miss a chance to show that your company actually listens to buyers.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By calling and transcribing your calls, you can learn all sorts of important lessons and get feedback from a larger segment of buyers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What kinds of language your buyers use to describe their problems. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Who else is involved in the buying decision. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What the buyer’s journey actually looks like rather than the idealized version of your marketing funnels.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Where your marketing falls short of meeting expectation.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Just doing two calls a day will give you 40 calls worth of information by the end of the month. With just 40 calls, you can start making better decisions about what goes on the homepage and product pages and what sorts of pages you should add to the site.&lt;/p&gt;

&lt;p&gt;As your volume of calls grows, you can segment this information by industry, persona, and funnel stage to get an even more granular understanding of your buyers. Eventually you can use the feedback to feed natural language processing libraries to further deepen your understanding and turn qualitative insight into quantitative insight.&lt;/p&gt;

&lt;p&gt;Qualitative feedback should be used to for test ideas, but don’t limit yourself to just informing your testing program. It should also help you better understand your buyers and make better decisions.&lt;/p&gt;

&lt;p&gt;Finally, it should be used in place of testing where a testing is difficult and takes too long.&lt;/p&gt;

&lt;p&gt;Testing the homepage against many competing internal and external priorities is a huge challenge.&lt;/p&gt;

&lt;p&gt;You could, for example, create a homepage that greatly increases the number of blog subscribers. You could even calculate that this improvement will have a greater impact on revenue than a smaller improvement that increases the number of opportunities. But, in making the pure numbers-based decision you could very easily choke off opportunities and waste those subscriber gains.&lt;/p&gt;

&lt;p&gt;Listening to feedback can help you make stronger decisions and can be a better alternative where A/B testing struggles.&lt;/p&gt;

&lt;h3&gt;A/B Testing Beyond the Browser&lt;/h3&gt;

&lt;p&gt;There’s one last form of testing that unequivocally belongs in a B-to-B testing program even if in a limited way.&lt;/p&gt;

&lt;p&gt;You can test your strategic marketing mix by removing different tactics from in different regions and measuring the results after a couple of sales cycles.&lt;/p&gt;

&lt;p&gt;Retargeting ads, for example, may look great because they touch every visitor before they become a customer. But do they have an impact? By definition they are shown to everyone who visits your site, or at least a specific page.&lt;/p&gt;

&lt;p&gt;If you want to know whether you are just sinking your money into retargeting, you’ll have to pull retargeting from a test region and measure the results after a couple of sales cycles.&lt;/p&gt;

&lt;p&gt;Field marketing, too, is another good candidate for this form of testing.&lt;/p&gt;

&lt;p&gt;What you do is pick a region and cut a tactic off from that region for a few sales cycles and then analyze the effect of the tactic on number of deals, average deal value, and total number of deals compared with other regions that didn’t cut that tactic off as well as historical data from within that region.&lt;/p&gt;

&lt;p&gt;This form of testing isn’t very challenging to implement and you will be testing things that help the CMO allocate budget and the CFO give more budget. You are somewhat limited in what you can test to marketing tactics that are wholly initiated by sales and marketing. A blog, for example, requires content that is initiated by marketing but also visitors who will find your blog independent of the region (and your control).&lt;/p&gt;

&lt;p&gt;Testing at the strategic level will make your testing program more valuable to the organization in a way that executives can better appreciate.&lt;/p&gt;

&lt;h2&gt;The Testing Role in B-to-B Marketing&lt;/h2&gt;

&lt;p&gt;There’s still plenty that you can learn from the commonly-shared ecommerce testing best practices but testing in a B-to-B setting presents a host of different challenges and you need to understand these challenges in order to have a successful testing program.&lt;/p&gt;

&lt;p&gt;Low traffic levels and long sales cycles limit the power of testing but that doesn’t mean it can’t be a powerful tool.&lt;/p&gt;

&lt;p&gt;Structuring your test program around understanding your buyers will not only help you overcome those limits but also improve the overall effectiveness of marketing beyond just the testing role.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Constellation Approach to Business Technology</title>
    <link rel="alternate" href="https://www.caretjuice.com/blog/constellation-approach-business-technology.html"/>
    <id>https://www.caretjuice.com/blog/constellation-approach-business-technology.html</id>
    <published>2016-03-14T17:00:00-07:00</published>
    <updated>2018-11-13T14:23:57-08:00</updated>
    <author>
      <name>Damon Gudaitis</name>
    </author>
    <summary type="html">&lt;p&gt;Self-driving cars promise to re-imagine the relationship between cities, people and transportation while Uber takes fat chunks out of the taxi industry. &lt;/p&gt;

&lt;p&gt;Newspapers struggle with relevance—the value of ad space having plummeted as the expense of publishing...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;Self-driving cars promise to re-imagine the relationship between cities, people and transportation while Uber takes fat chunks out of the taxi industry. &lt;/p&gt;

&lt;p&gt;Newspapers struggle with relevance—the value of ad space having plummeted as the expense of publishing dropped to near zero.&lt;/p&gt;

&lt;p&gt;Investors stand strong behind a company like Amazon while years of losses stretch into decades out of hope that it will one day turn its status as the default place where people go to buy online into an avalanche of profits that bury past losses.&lt;/p&gt;

&lt;p&gt;Technology is changing the business landscape quickly. But it isn’t just threatening old business models.&lt;/p&gt;

&lt;p&gt;New technology also brings new automation opportunities letting you and your colleagues get more done in less time.&lt;/p&gt;

&lt;p&gt;The Constellation Approach to Business Technology helps you understand business applications, how they relate to each other, and choose the best combination of technologies to balance growth, flexibility, and costs.&lt;/p&gt;

&lt;h2&gt;How Business Applications Have Changed in the Last 15+ Years&lt;/h2&gt;

&lt;p&gt;Until around the start of the new millennium, data stayed primarily within the business application. You’ve been able to integrate enterprise and legacy apps, but integration was time-consuming and expensive.&lt;/p&gt;

&lt;p&gt;As cloud computing grew in popularity and developing business software became cheaper, stand-alone applications focusing on solving increasingly niche problems flourished. Application programming interfaces (APIs) that let developers integrate apps became more common and then expected. APIs also started to become more consistent and easier to use alongside this explosion of options.&lt;/p&gt;

&lt;p&gt;The leading cloud applications in each category started using their APIs to build native integrations with each other. These integrations are at the point now where native integrations between the leading products in different software categories compete with and even exceed fully integrated suites.&lt;/p&gt;

&lt;p&gt;Upstart and niche cloud products emerged to solve increasingly specific problems.&lt;/p&gt;

&lt;p&gt;Typically these smaller products would be less expensive than the leading cloud options, and needed to integrate with the leaders in other applications categories in order to compete.&lt;/p&gt;

&lt;p&gt;Soon a variety of middleware applications would spring up giving you more integration options than native and custom integrations created by the respective product teams and their customers.&lt;/p&gt;

&lt;p&gt;Some of these middleware applications provided deep, powerful integrations between few products, like exporting Salesforce data to Excel and back.&lt;/p&gt;

&lt;p&gt;Others gave lots of shallow integrations between lots of different applications letting you trigger actions in one app from another or copying one field from one system to another.&lt;/p&gt;

&lt;table class="text-center table-text-top"&gt;
    &lt;tr&gt;
        &lt;th style="background-color:#ff8f4d; width:33%;"&gt;
            &lt;strong&gt;Enterprise Suite&lt;/strong&gt;
        &lt;/th&gt;
        &lt;th style="background-color:#86e400; width:33%;"&gt;
            &lt;strong&gt;Cloud Niche/Upstart&lt;/strong&gt;
        &lt;/th&gt;
        &lt;th style="background-color:#ff8f4d; width:33%;"&gt;
            &lt;strong&gt;Cloud Leader&lt;/strong&gt;
        &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td style="background-color:#ff8f4d; width:33%;"&gt;service partners build custom integrations&lt;/td&gt;
        &lt;td style="background-color:#86e400; width:33%;"&gt;develop own integrations&lt;/td&gt;
        &lt;td style="background-color:#ff8f4d; width:33%;"&gt;attract powerful integrations&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td style="background-color:#ff8f4d; width:33%;"&gt;costly to integrate&lt;/td&gt;
        &lt;td style="background-color:#86e400; width:33%;"&gt;moderately costly to integrate&lt;/td&gt;
        &lt;td style="background-color:#ff8f4d; width:33%;"&gt;low cost to integrate&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td style="background-color:#ff8f4d; width:33%;"&gt;costly to license&lt;/td&gt;
        &lt;td style="background-color:#86e400; width:33%;"&gt;inexpensive to license&lt;/td&gt;
        &lt;td style="background-color:#ff8f4d; width:33%;"&gt;moderately costly to license&lt;/td&gt;
    &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td colspan="3" style="border: 1px solid #B6B6B6;"&gt;&lt;strong&gt;Shallow Integration Middleware&lt;/strong&gt;&lt;br/&gt;
shallow integration between many applications&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td colspan="3" style="border: 1px solid #B6B6B6;"&gt;&lt;strong&gt;Deep Integration Middleware&lt;/strong&gt;&lt;br/&gt;
deep integration between a small number of applications&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;This explosion of stand-alone, SaaS business applications, with multiple layers of integration options, gives you more varied options towards solving a wider variety of challenges and unprecedented flexibility to manage the flow of information through your business.&lt;/p&gt;

&lt;p&gt;Where before you had to get an expensive piece of software that would require extensive configuration and customization before you could start using it effectively, now you can probably find a solution that will work for you almost immediately and at a lower cost.&lt;/p&gt;

&lt;h2&gt;The Hidden Cost of Cheap&lt;/h2&gt;

&lt;p&gt;Individual products and integrations are straightforward. The full web of products and integrations is incredibly complex.&lt;/p&gt;

&lt;p&gt;The overall cost of one or two low-cost, poorly integrated applications is negligible. Particularly if the applications solve an important business problem. Licensing and maintenance costs are practically non-existent in this situation.&lt;/p&gt;

&lt;p&gt;The costs of poorly integrated applications grow exponentially as their number increase. Licensing is still inexpensive, but niche products attract fewer integrations. And having substandard integration options imposes a substantial tax on productivity across the company. That tax increases with each application you add.&lt;/p&gt;

&lt;p&gt;The productivity tax is paid in the following ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;time spent on duplicate data entry&lt;/li&gt;
&lt;li&gt;poor decisions caused by poor data due to

&lt;ul&gt;
&lt;li&gt;data entry errors, and&lt;/li&gt;
&lt;li&gt;missing data&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;lost opportunity because highly specialized tools only integrate with the strongest platforms&lt;/li&gt;
&lt;li&gt;increased effort to perform what are basic tasks on stronger platforms.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While the cost each little example of duplicate data entry or handicapped decision making is negligible, they add up and quickly dwarf the licensing costs.&lt;/p&gt;

&lt;p&gt;Low-cost, niche products have their place in small businesses and solving niche problems in large ones. But their hidden costs are crippling the larger the business and more complex the technology stack.&lt;/p&gt;

&lt;h2&gt;Platforms and Solutions&lt;/h2&gt;

&lt;p&gt;If you’re not buying technology to solve a problem, then you are doing it wrong.&lt;/p&gt;

&lt;p&gt;When looking at an application, more features does not make a product better. In most cases, when you see a CRM that also does marketing automation, or a marketing automation suite that also has a content management system, or whatever other app that does something and something else, then the something else is almost always a very light version of an equivalent stand-alone app.&lt;/p&gt;

&lt;p&gt;It pays to be clear on what you are trying to accomplish with the software. Features are meaningless next to a great solution.&lt;/p&gt;

&lt;p&gt;When looking at business applications be aware of whether you need them to be a platform (and solution) or just a solution.&lt;/p&gt;

&lt;p&gt;Platforms are the core applications that you build off. They need to accommodate a variety of solutions as the company grows and they need to integrate readily with your other platforms.&lt;/p&gt;

&lt;p&gt;Niche products are often great solutions but lousy platforms because of the limited number of native integration options of a niche product. Your solutions need to integrate with one of your platforms, but any data that needs to go from solution to a non-integrated platform can usually get passed through via the one integrated platform.&lt;/p&gt;

&lt;p&gt;You don’t need extensive integration on a solution. Just one solid integration with a platform.&lt;/p&gt;

&lt;p&gt;Solutions are also great candidates for taking risky bets on new technologies because they sit at the edge of your network of applications and cause minimal disruption to your business. The cost of switching from one experimental solution to another is low if you have a good platform. &lt;/p&gt;

&lt;p&gt;This lets you outsource the risks of staying ahead of technology trends in your industry to venture capital firms while still reaping the benefits of cutting edge software technology investments.&lt;/p&gt;

&lt;p&gt;Once you start building on a platform, however, it is very difficult to switch. Each solution that you integrate with a platform is another requirement that will complicate purchasing, migrating and training if you ever grow out of the platform.&lt;/p&gt;

&lt;h2&gt;Expose Your Data&lt;/h2&gt;

&lt;p&gt;The most agile platforms for your business data, whether they be CRM, support, accounting software or even ERP, are the ones that best expose your data.&lt;/p&gt;

&lt;p&gt;New technologies like big data and machine learning are creating new opportunities every day. Marketing and finance are getting most of the love from new technologies right now with applications that do things like identify the best prospects or the biggest financial risks.&lt;/p&gt;

&lt;p&gt;Soon retailers will be able to do things like plug their point of sale and inventory data into a cloud app that will pull in weather data and forecast umbrella demand while adjusting the retail price to maximize revenue in real time.&lt;/p&gt;

&lt;p&gt;Niche Big Data solutions like weather-based inventory forecasts are multiplying quickly. Businesses don’t need a data scientist to benefit from the Big Data revolution—they just need to keep their data in platforms that attract lots of integrations.&lt;/p&gt;

&lt;h2&gt;The Constellation Approach to Business Technology&lt;/h2&gt;

&lt;p&gt;The Constellation Approach to Business Technology is meant as a way of understanding how your business applications relate to each other and what you need them to do so that you maximize flexibility, and minimize expenses without restricting growth.&lt;/p&gt;

&lt;p&gt;In order to apply this approach to your business, you need to do the following.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Identify platform categories (CRM, marketing automation, accounting) based on how you want to grow.&lt;/li&gt;
&lt;li&gt;Identify niche solutions that will contribute to your growth.&lt;/li&gt;
&lt;li&gt;Research integration options.&lt;/li&gt;
&lt;li&gt;Choose the combination of platforms, solutions and integrations that best balance cost, simplicity, flexibility, and future growth.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Everything in the Constellation Approach flows from understand which applications need to be platforms and then grows from there. The right platform both grows with you and gives you the best chance to take advantage of yet unimagined technologies just beyond the horizon.&lt;/p&gt;

&lt;p&gt;Innovation presents the greatest risks and rewards. A good platform will let you take advantage of innovative solutions while reducing the costs of switching or abandoning a solution.&lt;/p&gt;
</content>
  </entry>
</feed>
